VITE_API_URL=http://localhost:3001
MAX_BATCH_WORKERS=5
# ============================================================
# API PROVIDER CONFIGURATION
# ============================================================
# Set to "openai" or "openrouter"
API_PROVIDER=openai

# --- OpenAI (default) ---
OPENAI_API_KEY=your_openai_api_key_here

# --- OpenRouter ---
OPENROUTER_API_KEY=your_openrouter_api_key_here
# Optional: override the default OpenRouter base URL
# OPENROUTER_BASE_URL=https://openrouter.ai/api/v1

# ============================================================
# MODEL MAPPING (OpenRouter uses different model identifiers)
# ============================================================
# When API_PROVIDER=openrouter, model names from agent configs
# are automatically mapped. Override defaults here if needed:
#   gpt-4.1        -> openai/gpt-4.1
#   gpt-4o         -> openai/gpt-4o
#   gpt-4-turbo    -> openai/gpt-4-turbo
#   gpt-3.5-turbo  -> openai/gpt-3.5-turbo
# To use non-OpenAI models via OpenRouter, set the full model
# path in the agent config (e.g. "anthropic/claude-3.5-sonnet")

# ============================================================
# NODE IMPROVEMENT LLM MODELS
# ============================================================
# Comma-separated list of models available for node improvement
# Format: "Model Display Name:model-id"
VITE_IMPROVEMENT_MODELS=GPT-4.1:gpt-4.1,GPT-4o:gpt-4o,GPT-4 Turbo:gpt-4-turbo,Claude 3.5 Sonnet:anthropic/claude-3.5-sonnet

# Default temperature for node improvement (0.0 - 1.0)
VITE_DEFAULT_IMPROVEMENT_TEMPERATURE=0.7
