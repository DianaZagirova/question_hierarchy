# Omega Point - Configuration Template
# Copy this to .env and fill in your actual values

# Basic server settings
NODE_ENV=development
PORT=3002
HOST=0.0.0.0
VITE_API_URL=http://localhost:3002

# Choose your LLM provider: openai or openrouter
API_PROVIDER=openai

# Get your API keys from:
# OpenAI: https://platform.openai.com/api-keys
# OpenRouter: https://openrouter.ai/keys
OPENAI_API_KEY=your_openai_key_here
OPENROUTER_API_KEY=your_openrouter_key_here

# Worker configuration
# GUNICORN_WORKERS = roughly (2 x CPU cores) + 1
GUNICORN_WORKERS=4
GUNICORN_TIMEOUT=300
MAX_BATCH_WORKERS=5

# Which models show up in the node improvement dropdown
# Format: "Display Name:model-id"
VITE_IMPROVEMENT_MODELS=GPT-4.1:gpt-4.1,GPT-4o:gpt-4o,GPT-4 Turbo:gpt-4-turbo,Claude 3.5 Sonnet:anthropic/claude-3.5-sonnet
VITE_DEFAULT_IMPROVEMENT_TEMPERATURE=0.7

# Multi-user session support (requires PostgreSQL + Redis)
# For Docker, use 'postgres' and 'redis' as hostnames
# For local setup, use 'localhost'
DATABASE_URL=postgresql://omegapoint:changeme@postgres:5432/omegapoint
DB_PASSWORD=changeme
REDIS_URL=redis://redis:6379/0
SESSION_EXPIRY_DAYS=7
