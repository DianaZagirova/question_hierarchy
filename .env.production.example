# ============================================================
# OMEGA-POINT Production Environment
# ============================================================
# Copy this file to .env and fill in your values:
#   cp .env.production.example .env
MAX_BATCH_WORKERS=5
# Server
NODE_ENV=production
PORT=3001
HOST=0.0.0.0

# Frontend API URL â€” in production the Flask server serves both
# the API and the built frontend on the same origin.
# Set this to your server's public URL (no trailing slash).
VITE_API_URL=

# ============================================================
# API PROVIDER CONFIGURATION
# ============================================================
# "openai" or "openrouter"
API_PROVIDER=openai

# --- OpenAI (default) ---
OPENAI_API_KEY=

# --- OpenRouter (alternative) ---
# OPENROUTER_API_KEY=
# OPENROUTER_BASE_URL=https://openrouter.ai/api/v1

# ============================================================
# GUNICORN (production WSGI server)
# ============================================================
# Number of worker processes (rule of thumb: 2 * CPU cores + 1)
GUNICORN_WORKERS=4
# Request timeout in seconds (LLM calls can be slow)
GUNICORN_TIMEOUT=300
